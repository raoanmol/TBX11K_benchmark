# TBX11K Ã— Mask R-CNN Benchmark

Reproducible experiments comparing **Mask R-CNN** trained from scratch vs. fine-tuned from ImageNet on the TBX11K tuberculosis detection dataset.

## ğŸ“‹ Overview

This repository implements a rigorous experimental pipeline to answer:

> **Does ImageNet pre-training improve tuberculosis lesion detection compared to training from scratch?**

The pipeline includes:
- âœ… Automatic dataset discovery and standardization
- âœ… 10 independent runs per condition (scratch vs. fine-tuned)
- âœ… Deterministic training with full reproducibility
- âœ… FROC (Free-Response ROC) evaluation
- âœ… Statistical significance testing (paired t-test, Wilcoxon)
- âœ… Complete logging and experiment tracking

---

## ğŸ—ï¸ Project Structure

```
TBX11K_benchmark/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ TBX11K/                     # Original dataset (auto-discovered)
â”‚   â”‚   â”œâ”€â”€ imgs/                   # Images organized by category
â”‚   â”‚   â”œâ”€â”€ annotations/            # JSON and XML annotations
â”‚   â”‚   â””â”€â”€ lists/                  # Train/val/test splits
â”‚   â””â”€â”€ processed/                  # Standardized COCO format
â”‚       â”œâ”€â”€ train.json
â”‚       â”œâ”€â”€ val.json
â”‚       â”œâ”€â”€ test.json
â”‚       â””â”€â”€ debug_samples/          # Validation visualizations
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ phase1_dataset_discovery.py    # Auto-discover dataset structure
â”‚   â”œâ”€â”€ phase2_standardization.py      # Convert to COCO format
â”‚   â””â”€â”€ phase3_validation.py           # Validate with visualizations
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py                  # PyTorch dataset loader
â”‚   â”œâ”€â”€ model.py                    # Mask R-CNN model setup
â”‚   â”œâ”€â”€ train.py                    # Training script
â”‚   â”œâ”€â”€ evaluate_froc.py            # FROC computation
â”‚   â””â”€â”€ statistical_analysis.py     # Statistical testing
â”‚
â”œâ”€â”€ experiments/                    # Training outputs (created during runs)
â”‚   â”œâ”€â”€ maskrcnn_scratch/
â”‚   â”‚   â”œâ”€â”€ run_00/ ... run_09/
â”‚   â””â”€â”€ maskrcnn_finetune/
â”‚       â””â”€â”€ run_00/ ... run_09/
â”‚
â”œâ”€â”€ outputs/                        # Final analysis results
â”‚   â”œâ”€â”€ aggregated_results.json
â”‚   â”œâ”€â”€ final_statistics.json
â”‚   â”œâ”€â”€ froc_mean_plot.png
â”‚   â””â”€â”€ boxplot_comparison.png
â”‚
â”œâ”€â”€ run_experiments.py              # Master experiment runner
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Prepare Dataset

The dataset should already be in `./data/TBX11K/`. If not, download it first.

```bash
# Step 1: Discover dataset structure
python scripts/phase1_dataset_discovery.py

# Step 2: Standardize to COCO format
python scripts/phase2_standardization.py

# Step 3: Validate with visualizations
python scripts/phase3_validation.py
```

**Expected output:**
```
âœ… ALL VALIDATIONS PASSED - Dataset ready for training
```

You can view validation samples in `data/processed/debug_samples/`.

### 3. Run Full Experiment Pipeline

**Option A: Full pipeline (20 runs total, ~40-80 hours on GPU)**

```bash
python run_experiments.py \
    --n-runs 10 \
    --num-epochs 20 \
    --batch-size 2 \
    --learning-rate 0.005
```

**Option B: Quick test (1 run each, ~2-4 hours)**

```bash
python run_experiments.py \
    --n-runs 1 \
    --num-epochs 5 \
    --batch-size 2
```

**Option C: Run individual experiments**

```bash
# Scratch training (single run)
python src/train.py \
    --train-json ./data/processed/train.json \
    --val-json ./data/processed/val.json \
    --image-root ./data/TBX11K/imgs \
    --experiment-name maskrcnn_scratch \
    --run-id 0 \
    --output-dir ./experiments/maskrcnn_scratch/run_00 \
    --seed 42 \
    --num-epochs 20 \
    --batch-size 2

# Fine-tuned training (single run)
python src/train.py \
    --train-json ./data/processed/train.json \
    --val-json ./data/processed/val.json \
    --image-root ./data/TBX11K/imgs \
    --pretrained-backbone \
    --experiment-name maskrcnn_finetune \
    --run-id 0 \
    --output-dir ./experiments/maskrcnn_finetune/run_00 \
    --seed 42 \
    --num-epochs 20 \
    --batch-size 2
```

### 4. Evaluate FROC

```bash
python src/evaluate_froc.py \
    --eval-json ./data/processed/val.json \
    --image-root ./data/TBX11K/imgs \
    --checkpoint ./experiments/maskrcnn_scratch/run_00/checkpoints/best_model.pth \
    --output-dir ./experiments/maskrcnn_scratch/run_00/eval
```

### 5. Statistical Analysis

```bash
python src/statistical_analysis.py \
    --scratch-dir ./experiments/maskrcnn_scratch \
    --finetune-dir ./experiments/maskrcnn_finetune \
    --n-runs 10 \
    --output-dir ./outputs
```

---

## ğŸ“Š Expected Results

After running the full pipeline, you'll find:

### Training Logs
- `experiments/maskrcnn_scratch/run_XX/logs/training_log.json` - Loss curves, best epoch
- `experiments/maskrcnn_scratch/run_XX/checkpoints/best_model.pth` - Best model checkpoint

### FROC Evaluation
- `experiments/maskrcnn_scratch/run_XX/eval/froc.csv` - Full FROC curve data
- `experiments/maskrcnn_scratch/run_XX/eval/froc_interpolated.json` - Sensitivity at key FP rates
- `experiments/maskrcnn_scratch/run_XX/eval/froc_curve.png` - Visualization

### Statistical Analysis
- `outputs/final_statistics.json` - Paired t-test, Wilcoxon, Cohen's d
- `outputs/aggregated_results.json` - All run results
- `outputs/froc_mean_plot.png` - Mean FROC curves with std dev
- `outputs/boxplot_comparison.png` - Distribution comparison at FP=1

---

## ğŸ”¬ Methodology

### Dataset
- **TBX11K**: 12,279 chest X-ray images
- **Classes**: 3 tuberculosis types (ActiveTB, ObsoletePulmonaryTB, PulmonaryTB)
- **Annotations**: 1,211 bounding boxes (902 train, 309 val)
- **Split**: 6,600 train / 1,800 val / 3,302 test (unlabeled)

### Model
- **Architecture**: Mask R-CNN with ResNet-50 FPN backbone
- **Conditions**:
  1. **Scratch**: Random initialization
  2. **Fine-tuned**: ImageNet-pretrained backbone

### Training
- **Epochs**: 20 (configurable)
- **Batch size**: 2
- **Optimizer**: SGD (lr=0.005, momentum=0.9, weight_decay=0.0005)
- **LR Schedule**: StepLR (step=5, gamma=0.1)
- **Determinism**: Fixed seeds, cudnn.deterministic=True

### Evaluation
- **Metric**: FROC (Free-Response ROC)
- **IoU threshold**: 0.5
- **Key FP rates**: [0.125, 0.25, 0.5, 1, 2, 4] FP per image
- **Primary comparison**: Sensitivity at FP/image = 1.0

### Statistical Testing
- **Paired t-test** (parametric)
- **Wilcoxon signed-rank test** (non-parametric)
- **Effect size**: Cohen's d
- **Significance level**: Î± = 0.05

---

## ğŸ”§ Configuration

### Key Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--n-runs` | 10 | Number of runs per experiment |
| `--base-seed` | 42 | Base random seed (run i = base_seed + i) |
| `--num-epochs` | 20 | Training epochs |
| `--batch-size` | 2 | Batch size |
| `--learning-rate` | 0.005 | Initial learning rate |

### Computational Requirements

**Minimum (1 run, 5 epochs):**
- GPU: 8GB VRAM (e.g., GTX 1080)
- Time: ~2 hours per run

**Recommended (10 runs, 20 epochs):**
- GPU: 16GB+ VRAM (e.g., RTX 3090, V100)
- Time: ~40-80 hours total
- Storage: ~20GB for checkpoints

**CPU-only mode:**
- Possible but ~10-20x slower
- Not recommended for full experiments

---

## ğŸ“ Reproducibility Checklist

This implementation ensures full reproducibility:

- âœ… Fixed random seeds (PyTorch, NumPy, Python)
- âœ… Deterministic CUDA operations
- âœ… Recorded environment info (PyTorch/CUDA versions, GPU model)
- âœ… Saved exact configurations per run
- âœ… Dataset hash verification
- âœ… Deterministic data loader shuffling
- âœ… Complete logging of all hyperparameters
- âœ… Error handling with full stack traces

---

## ğŸ› Troubleshooting

### Issue: CUDA out of memory

**Solution:**
```bash
# Reduce batch size
python run_experiments.py --batch-size 1
```

### Issue: Missing dataset files

**Solution:**
```bash
# Re-run discovery and standardization
python scripts/phase1_dataset_discovery.py
python scripts/phase2_standardization.py
python scripts/phase3_validation.py
```

### Issue: Import errors

**Solution:**
```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

### Issue: Training crashes mid-run

**Solution:**
- Check `experiments/*/run_XX/error.log` for stack trace
- Training automatically saves checkpoints, can resume if needed
- Each run is independent, failed runs don't block others

---

## ğŸ“š References

- **TBX11K Dataset**: Liu et al., "Rethinking Computer-Aided Tuberculosis Diagnosis" (CVPR 2020)
- **Mask R-CNN**: He et al., "Mask R-CNN" (ICCV 2017)
- **FROC Analysis**: Chakraborty & Berbaum, "Observer studies involving detection and localization" (2004)

---

## ğŸ“„ License

This code is provided for research purposes. The TBX11K dataset has its own license terms.

---

## ğŸ™ Acknowledgments

- TBX11K dataset authors
- PyTorch and torchvision teams
- Medical imaging community

---

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue or contact the repository maintainer.

---

**Last updated:** 2026-02-20
